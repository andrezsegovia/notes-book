# 2..1.2. Conjuntó de Datos Externo

Spark puede crear RDD por cualquier fuente de almacenamiento soportada por Hadoop, esto incluye el sistema de archivos local, HDFS, Cassandra, HBase, Amazon S3, etc. Soporta archivos de texto, SequenceFiles, y cualquiera otro Hadoop InputFormant.

Se crean con el método ``textFile`` de ``SparkContext``, el cual acepta como primer parámetro la URI del archivo y como segundo parámetro, aunque opcional, la cantidad de particiones del archivo. La cantidad de particiones no puede ser menor que la de bloques.

```scala
val distFile = sc.textFile(¨data.text¨, 10)
```



---

#### Referencias

- Spark Programing Guide [ver](

